{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Config\n",
    "\n",
    "from tokenization_enc_dec import EncDecTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EncDecTokenizer('./EVA/src/bpe_dialog_new/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = T5Config(\n",
    "    vocab_size=30000,\n",
    "    # n_positions=self.n_positions,\n",
    "    d_model=2048,\n",
    "    d_ff=5120,\n",
    "    d_kv=2048 // 32,\n",
    "    num_layers=24,\n",
    "    num_heads=32,\n",
    "    relative_attention_num_buckets=32,\n",
    "    dropout_rate=0.0,\n",
    "    initializer_factor=1.0,\n",
    "    eos_token_id=tokenizer.eod_id,\n",
    "    bos_token_id=tokenizer.pad_id,\n",
    "    pad_token_id=tokenizer.pad_id,\n",
    "    decoder_start_token_id=tokenizer.pad_id,\n",
    "    feed_forward_proj='gated-gelu',\n",
    "    tie_word_embeddings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model(input_ids=torch.LongTensor([[1]]), decoder_input_ids=torch.LongTensor([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight torch.Size([30000, 2048])\n",
      "encoder.embed_tokens.weight torch.Size([30000, 2048])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 32])\n",
      "encoder.block.0.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.0.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.1.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.1.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.2.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.2.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.3.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.3.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.4.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.4.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.5.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.5.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.6.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.6.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.7.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.7.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.8.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.8.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.8.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.8.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.8.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.8.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.8.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.9.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.9.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.9.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.9.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.9.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.9.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.9.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.10.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.10.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.10.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.10.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.10.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.10.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.10.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.11.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.11.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.11.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.11.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.11.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.11.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.11.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.12.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.12.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.12.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.12.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.12.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.12.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.12.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.12.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.12.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.13.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.13.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.13.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.13.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.13.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.13.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.13.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.13.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.13.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.14.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.14.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.14.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.14.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.14.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.14.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.14.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.14.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.14.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.15.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.15.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.15.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.15.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.15.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.15.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.15.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.15.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.15.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.16.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.16.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.16.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.16.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.16.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.16.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.16.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.16.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.16.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.17.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.17.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.17.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.17.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.17.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.17.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.17.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.17.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.17.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.18.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.18.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.18.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.18.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.18.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.18.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.18.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.18.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.18.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.19.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.19.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.19.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.19.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.19.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.19.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.19.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.19.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.19.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.20.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.20.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.20.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.20.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.20.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.20.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.20.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.20.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.20.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.21.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.21.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.21.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.21.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.21.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.21.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.21.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.21.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.21.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.22.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.22.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.22.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.22.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.22.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.22.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.22.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.22.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.22.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.23.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "encoder.block.23.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "encoder.block.23.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "encoder.block.23.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "encoder.block.23.layer.0.layer_norm.weight torch.Size([2048])\n",
      "encoder.block.23.layer.1.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.block.23.layer.1.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.block.23.layer.1.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.block.23.layer.1.layer_norm.weight torch.Size([2048])\n",
      "encoder.final_layer_norm.weight torch.Size([2048])\n",
      "decoder.embed_tokens.weight torch.Size([30000, 2048])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 32])\n",
      "decoder.block.0.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.0.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.0.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.1.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.1.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.1.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.2.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.2.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.2.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.3.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.3.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.3.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.4.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.4.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.4.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.5.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.5.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.5.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.6.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.6.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.6.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.7.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.7.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.7.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.8.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.8.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.8.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.8.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.8.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.8.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.8.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.8.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.8.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.8.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.8.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.8.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.9.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.9.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.9.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.9.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.9.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.9.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.9.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.9.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.9.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.9.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.9.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.9.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.10.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.10.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.10.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.10.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.10.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.10.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.10.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.10.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.10.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.10.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.10.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.10.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.11.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.11.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.11.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.11.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.11.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.11.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.11.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.11.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.11.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.11.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.11.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.11.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.12.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.12.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.12.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.12.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.12.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.12.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.12.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.12.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.12.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.12.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.12.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.12.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.12.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.12.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.13.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.13.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.13.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.13.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.13.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.13.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.13.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.13.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.13.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.13.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.13.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.13.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.13.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.13.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.14.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.14.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.14.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.14.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.14.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.14.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.14.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.14.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.14.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.14.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.14.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.14.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.14.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.14.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.15.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.15.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.15.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.15.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.15.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.15.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.15.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.15.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.15.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.15.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.15.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.15.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.15.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.15.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.16.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.16.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.16.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.16.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.16.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.16.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.16.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.16.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.16.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.16.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.16.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.16.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.16.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.16.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.17.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.17.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.17.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.17.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.17.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.17.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.17.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.17.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.17.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.17.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.17.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.17.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.17.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.17.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.18.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.18.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.18.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.18.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.18.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.18.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.18.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.18.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.18.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.18.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.18.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.18.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.18.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.18.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.19.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.19.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.19.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.19.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.19.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.19.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.19.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.19.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.19.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.19.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.19.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.19.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.19.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.19.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.20.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.20.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.20.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.20.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.20.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.20.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.20.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.20.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.20.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.20.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.20.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.20.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.20.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.20.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.21.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.21.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.21.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.21.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.21.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.21.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.21.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.21.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.21.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.21.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.21.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.21.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.21.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.21.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.22.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.22.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.22.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.22.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.22.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.22.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.22.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.22.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.22.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.22.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.22.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.22.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.22.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.22.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.23.layer.0.SelfAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.23.layer.0.SelfAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.23.layer.0.SelfAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.23.layer.0.SelfAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.23.layer.0.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.23.layer.1.EncDecAttention.q.weight torch.Size([2048, 2048])\n",
      "decoder.block.23.layer.1.EncDecAttention.k.weight torch.Size([2048, 2048])\n",
      "decoder.block.23.layer.1.EncDecAttention.v.weight torch.Size([2048, 2048])\n",
      "decoder.block.23.layer.1.EncDecAttention.o.weight torch.Size([2048, 2048])\n",
      "decoder.block.23.layer.1.layer_norm.weight torch.Size([2048])\n",
      "decoder.block.23.layer.2.DenseReluDense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.block.23.layer.2.DenseReluDense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.block.23.layer.2.DenseReluDense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.block.23.layer.2.layer_norm.weight torch.Size([2048])\n",
      "decoder.final_layer_norm.weight torch.Size([2048])\n",
      "lm_head.weight torch.Size([30000, 2048])\n"
     ]
    }
   ],
   "source": [
    "# transformers的T5是把QKV分开的\n",
    "for k, v in model.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def load_dtype(fp):\n",
    "    v = struct.unpack(\"B\", fp.read(1))[0]\n",
    "    if v == 0:\n",
    "        return np.int8\n",
    "    elif v == 1:\n",
    "        return np.float16\n",
    "    elif v == 2:\n",
    "        return np.float32\n",
    "    else:\n",
    "        raise TypeError(\"Unknown dtype %d\" % v)\n",
    "\n",
    "def load_string(fp):\n",
    "    size = struct.unpack(\"I\", fp.read(4))[0]\n",
    "    v = fp.read(size)\n",
    "    return v.decode(\"utf-8\")\n",
    "\n",
    "def load_tuple(fp):\n",
    "    dim_tuple = struct.unpack(\"B\", fp.read(1))[0]\n",
    "    ret = []\n",
    "    for _ in range(dim_tuple):\n",
    "        ret.append(struct.unpack(\"I\", fp.read(4))[0]) \n",
    "    return tuple(ret)\n",
    "\n",
    "def load_parameter(fp):    \n",
    "    shape = load_tuple(fp)\n",
    "    value_size = struct.unpack(\"I\", fp.read(4))[0]\n",
    "    dtype = load_dtype(fp)\n",
    "    value = fp.read(value_size)\n",
    "    return shape, value, dtype\n",
    "\n",
    "def load(fp, parent_name=''):\n",
    "    num_parameters, num_sub_layers = struct.unpack(\"II\", fp.read(8))\n",
    "    parameters = []\n",
    "\n",
    "    for _ in range(num_parameters):\n",
    "        name = load_string(fp)\n",
    "        shape, value, dtype = load_parameter(fp)\n",
    "        parameters.append((parent_name + '.' + name, np.frombuffer(value, dtype).reshape(shape)))\n",
    "    for _ in range(num_sub_layers):\n",
    "        name = load_string(fp)\n",
    "        parameters += load(fp, parent_name + '.' + name)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../zhiyuan/eva/checkpoint.pt', 'rb') as fp:\n",
    "    parameters = load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindex = {x[0]: x[1] for x in parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704/704 [00:44<00:00, 15.65it/s]\n"
     ]
    }
   ],
   "source": [
    "npara = {}\n",
    "for name, value in tqdm(parameters):\n",
    "    if '_scale' not in name:\n",
    "        has_scale = name + '_scale'\n",
    "        if has_scale in pindex:\n",
    "            scale = pindex[has_scale]\n",
    "            value = value.astype(np.float16) * scale\n",
    "        npara[name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(n):\n",
    "    params = []\n",
    "    for k, v in npara.items():\n",
    "        if n == 0 and '.encoder_position_bias.embedding.weight' in k:\n",
    "            params.append((\n",
    "                'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
    "                v,\n",
    "            ))\n",
    "        if f'.encoder.{n}.' in k:\n",
    "            if 'self_attention.w_project_qkv' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.SelfAttention.q.weight',\n",
    "                    v[0]\n",
    "                ))\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.SelfAttention.k.weight',\n",
    "                    v[1]\n",
    "                ))\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.SelfAttention.v.weight',\n",
    "                    v[2]\n",
    "                ))\n",
    "            if 'self_attention.w_out' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.SelfAttention.o.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_self_attn.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wi_0.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.1.DenseReluDense.wi_0.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wi_1.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.1.DenseReluDense.wi_1.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wo.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.1.DenseReluDense.wo.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_ff.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.1.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(n):\n",
    "    params = []\n",
    "    for k, v in npara.items():\n",
    "        if n == 0 and '.decoder_position_bias.embedding.weight' in k:\n",
    "            params.append((\n",
    "                'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
    "                v,\n",
    "            ))\n",
    "        if f'.decoder.{n}.' in k:\n",
    "            if 'self_attention.w_project_qkv' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.SelfAttention.q.weight',\n",
    "                    v[0]\n",
    "                ))\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.SelfAttention.k.weight',\n",
    "                    v[1]\n",
    "                ))\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.SelfAttention.v.weight',\n",
    "                    v[2]\n",
    "                ))\n",
    "            if 'self_attention.w_out' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.SelfAttention.o.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_self_attn.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "                \n",
    "            if '.cross_attention.w_project_q' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.1.EncDecAttention.q.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if '.cross_attention.w_out' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.1.EncDecAttention.o.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_cross_attn.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.1.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "\n",
    "            if 'dense_gelu_dense.wi_0.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.2.DenseReluDense.wi_0.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wi_1.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.2.DenseReluDense.wi_1.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wo.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.2.DenseReluDense.wo.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_ff.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.2.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "#     params.append((\n",
    "#         f'decoder.block.{n}.layer.1.EncDecAttention.k.weight',\n",
    "#         npara[f'.encoder.{n}.self_attention.w_project_qkv'][1]\n",
    "#     ))\n",
    "#     params.append((\n",
    "#         f'decoder.block.{n}.layer.1.EncDecAttention.v.weight',\n",
    "#         npara[f'.encoder.{n}.self_attention.w_project_qkv'][2]\n",
    "#     ))\n",
    "    params.append((\n",
    "        f'decoder.block.{n}.layer.1.EncDecAttention.k.weight',\n",
    "        npara['.encoder_kv.w_project_kv'][n][0]\n",
    "    ))\n",
    "    params.append((\n",
    "        f'decoder.block.{n}.layer.1.EncDecAttention.v.weight',\n",
    "        npara['.encoder_kv.w_project_kv'][n][1]\n",
    "    ))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = []\n",
    "new_state_dict.append((\n",
    "    'shared.weight',\n",
    "    npara['.input_embedding.weight'],\n",
    "))\n",
    "new_state_dict.append((\n",
    "    'encoder.embed_tokens.weight',\n",
    "    npara['.input_embedding.weight'],\n",
    "))\n",
    "\n",
    "for i in range(24):\n",
    "    new_state_dict += get_encoder(i)\n",
    "\n",
    "new_state_dict.append((\n",
    "    'encoder.final_layer_norm.weight',\n",
    "    npara['.encoder_final_layer_nrom.weight'],\n",
    "))\n",
    "\n",
    "new_state_dict.append((\n",
    "    'decoder.embed_tokens.weight',\n",
    "    npara['.input_embedding.weight'],\n",
    "))\n",
    "\n",
    "for i in range(24):\n",
    "    new_state_dict += get_decoder(i)\n",
    "\n",
    "new_state_dict.append((\n",
    "    'decoder.final_layer_norm.weight',\n",
    "    npara['.decoder_final_layer_nrom.weight'],\n",
    "))\n",
    "\n",
    "new_state_dict.append((\n",
    "    'lm_head.weight',\n",
    "    npara['.lm_head.weight'],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict({\n",
    "    k: torch.from_numpy(v)\n",
    "    for k, v in new_state_dict\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喜\n",
      "喜欢\n",
      "喜欢啊\n",
      "喜欢啊,\n",
      "喜欢啊,但\n",
      "喜欢啊,但是\n",
      "喜欢啊,但是我\n",
      "喜欢啊,但是我不\n",
      "喜欢啊,但是我不喜\n",
      "喜欢啊,但是我不喜欢\n"
     ]
    }
   ],
   "source": [
    "decoder_input = [tokenizer.get_sentinel_id(0)]\n",
    "input_ids = torch.LongTensor([\n",
    "    tokenizer.encode('你喜欢郭德纲吗？') + [tokenizer.sep_id, tokenizer.get_sentinel_id(0)]])\n",
    "\n",
    "for i in range(10):\n",
    "    decoder_input_ids = torch.LongTensor([decoder_input])\n",
    "    outputs = model(input_ids, decoder_input_ids=decoder_input_ids)\n",
    "    next_tokens = np.argsort(outputs.logits[0, -1, :].detach().numpy())\n",
    "    next_tokens = next_tokens[::-1]\n",
    "    next_token = next_tokens[0]\n",
    "    decoder_input.append(next_token)\n",
    "    print(tokenizer.decode(decoder_input[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喜欢啊\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.LongTensor([\n",
    "    tokenizer.encode('你喜欢郭德纲吗') + [tokenizer.sep_id, tokenizer.get_sentinel_id(0)]]\n",
    ")\n",
    "out = model.generate(\n",
    "    input_ids,\n",
    "    decoder_start_token_id=tokenizer.get_sentinel_id(0),\n",
    "    eos_token_id=tokenizer.sep_id,\n",
    "    do_sample=True,\n",
    "    top_p=0.85,\n",
    "    top_k=10\n",
    ")\n",
    "out_text = tokenizer.decode(out.numpy()[0].tolist()[1:-1])\n",
    "print(out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>你好\n",
      "您好,请问有什么问题小妹可以帮您处理或解决呢?\n",
      ">>>你能做啥啊\n",
      "亲亲,您方便简单描述下您的问题吗?\n",
      ">>>你喜欢郭德纲吗\n",
      "嗯嗯亲亲您方便简单描述下您的问题吗?\n",
      ">>>你喜欢郭德纲吗\n",
      "喜欢呀\n",
      ">>>你听过他的什么？\n",
      "亲亲是在哪啊\n",
      ">>>\n"
     ]
    }
   ],
   "source": [
    "sentence = []\n",
    "\n",
    "while True:\n",
    "    text = input('>>>')\n",
    "    if text == 'quit' or len(text.strip()) <= 0:\n",
    "        break\n",
    "    sentence.append(text)\n",
    "\n",
    "    input_ids = []\n",
    "    for x in sentence:\n",
    "        input_ids += tokenizer.encode(x) + [tokenizer.sep_id]\n",
    "    input_ids += [tokenizer.get_sentinel_id(0)]\n",
    "    input_ids = torch.LongTensor([input_ids])\n",
    "    \n",
    "    out = model.generate(\n",
    "        input_ids,\n",
    "        decoder_start_token_id=tokenizer.get_sentinel_id(0),\n",
    "        eos_token_id=tokenizer.sep_id,\n",
    "        do_sample=True,\n",
    "        top_p=0.85,\n",
    "        top_k=10\n",
    "    )\n",
    "    out_text = tokenizer.decode(out.numpy()[0].tolist()[1:-1])\n",
    "    print(out_text)\n",
    "    sentence.append(out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained('./torch_eva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_text = '你好'\n",
    "# decode_text = '你也好啊'\n",
    "# input_ids = tokenizer.encode(input_text) + [tokenizer.sep_id, tokenizer.get_sentinel_id(0)]\n",
    "# decoder_input_ids = [tokenizer.get_sentinel_id(0)] + tokenizer.encode(decode_text)\n",
    "# labels = tokenizer.encode(decode_text) + [tokenizer.sep_id]\n",
    "# out = model(\n",
    "#     torch.LongTensor(input_ids).unsqueeze(0),\n",
    "#     decoder_input_ids=torch.LongTensor(decoder_input_ids).unsqueeze(0),\n",
    "#     labels=torch.LongTensor(labels).unsqueeze(0))\n",
    "# out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
