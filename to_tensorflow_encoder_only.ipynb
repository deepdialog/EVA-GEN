{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import TFT5EncoderModel, TFT5Model\n",
    "from transformers import T5Config\n",
    "\n",
    "from tokenization_enc_dec import EncDecTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EncDecTokenizer('./EVA/src/bpe_dialog_new/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp_rank_00_model_states.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../eva-ckpt/222500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('../eva-ckpt/222500/mp_rank_00_model_states.pt', map_location='cpu')['module']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeds.weight torch.Size([30000, 2048])\n",
      "lm_head.weight torch.Size([30000, 2048])\n",
      "encoder.word_embeds.weight torch.Size([30000, 2048])\n",
      "encoder.final_layernorm.weight torch.Size([2048])\n",
      "encoder.blocks.0.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.0.self_attn.self_attn.relative_attention_bias.weight torch.Size([32, 32])\n",
      "encoder.blocks.0.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.0.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.0.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.1.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.1.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.1.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.1.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.2.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.2.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.2.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.2.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.3.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.3.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.3.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.3.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.4.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.4.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.4.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.4.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.5.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.5.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.5.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.5.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.6.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.6.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.6.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.6.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.7.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.7.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.7.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.7.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.8.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.8.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.8.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.8.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.9.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.9.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.9.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.9.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.10.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.10.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.10.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.10.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.11.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.11.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.11.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.11.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.12.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.12.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.12.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.12.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.13.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.13.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.13.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.13.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.14.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.14.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.14.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.14.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.15.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.15.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.15.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.15.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.16.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.16.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.16.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.16.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.17.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.17.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.17.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.17.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.18.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.18.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.18.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.18.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.19.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.19.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.19.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.19.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.20.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.20.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.20.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.20.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.21.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.21.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.21.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.21.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.22.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.22.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.22.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.22.ff.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.23.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "encoder.blocks.23.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "encoder.blocks.23.self_attn.layer_norm.weight torch.Size([2048])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "encoder.blocks.23.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.word_embeds.weight torch.Size([30000, 2048])\n",
      "decoder.final_layernorm.weight torch.Size([2048])\n",
      "decoder.blocks.0.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.0.self_attn.self_attn.relative_attention_bias.weight torch.Size([32, 32])\n",
      "decoder.blocks.0.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.0.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.0.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.0.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.0.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.0.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.0.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.1.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.1.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.1.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.1.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.1.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.1.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.1.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.1.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.2.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.2.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.2.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.2.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.2.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.2.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.2.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.2.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.3.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.3.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.3.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.3.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.3.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.3.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.3.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.3.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.4.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.4.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.4.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.4.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.4.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.4.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.4.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.4.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.5.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.5.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.5.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.5.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.5.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.5.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.5.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.5.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.6.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.6.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.6.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.6.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.6.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.6.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.6.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.6.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.7.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.7.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.7.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.7.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.7.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.7.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.7.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.7.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.8.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.8.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.8.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.8.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.8.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.8.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.8.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.8.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.9.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.9.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.9.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.9.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.9.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.9.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.9.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.9.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.10.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.10.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.10.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.10.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.10.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.10.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.10.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.10.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.11.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.11.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.11.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.11.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.11.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.11.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.11.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.11.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.12.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.12.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.12.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.12.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.12.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.12.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.12.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.12.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.13.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.13.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.13.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.13.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.13.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.13.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.13.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.13.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.14.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.14.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.14.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.14.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.14.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.14.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.14.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.14.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.15.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.15.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.15.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.15.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.15.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.15.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.15.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.15.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.16.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.16.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.16.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.16.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.16.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.16.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.16.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.16.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.17.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.17.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.17.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.17.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.17.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.17.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.17.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.17.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.18.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.18.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.18.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.18.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.18.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.18.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.18.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.18.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.19.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.19.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.19.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.19.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.19.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.19.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.19.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.19.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.20.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.20.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.20.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.20.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.20.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.20.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.20.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.20.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.21.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.21.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.21.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.21.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.21.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.21.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.21.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.21.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.22.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.22.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.22.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.22.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.22.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.22.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.22.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.22.ff.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.23.self_attn.self_attn.project.weight torch.Size([6144, 2048])\n",
      "decoder.blocks.23.self_attn.self_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.23.self_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.23.cross_attn.cross_attn.project_q.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.23.cross_attn.cross_attn.project_kv.weight torch.Size([4096, 2048])\n",
      "decoder.blocks.23.cross_attn.cross_attn.dense.weight torch.Size([2048, 2048])\n",
      "decoder.blocks.23.cross_attn.layer_norm.weight torch.Size([2048])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wi_0.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wi_1.weight torch.Size([5120, 2048])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wo.weight torch.Size([2048, 5120])\n",
      "decoder.blocks.23.ff.layer_norm.weight torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "# 注意encoder和decoder的blocks.0和其他的1,2,3...23不一样，0多了relative_attention_bias\n",
    "for k, v in state_dict.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(name):\n",
    "    return state_dict[name].numpy()\n",
    "\n",
    "\n",
    "def get_block_weight(n, t='encoder', name=False, dim=2048):\n",
    "    weights = []\n",
    "    for k, v in state_dict.items():\n",
    "        if t in k and f'blocks.{n}.' in k:\n",
    "            # pytorch和tensorflow版本的weights是矩阵转置的\n",
    "            w = v.numpy()\n",
    "            if 'self_attn.project' in k:\n",
    "                w0, w1, w2 = w[:dim, :], w[dim:dim*2, :], w[dim*2:, :]\n",
    "                w0 = np.transpose(w0)\n",
    "                w1 = np.transpose(w1)\n",
    "                w2 = np.transpose(w2)\n",
    "                weights.append((k, w0))\n",
    "                weights.append((k, w1))\n",
    "                weights.append((k, w2))\n",
    "            elif 'cross_attn.project_q' in k:\n",
    "                w = np.transpose(w)\n",
    "                weights.append((k, w))\n",
    "            elif 'cross_attn.project_kv' in k:\n",
    "                w0, w1 = w[:dim, :], w[dim:, :]\n",
    "                w0 = np.transpose(w0)\n",
    "                w1 = np.transpose(w1)\n",
    "                weights.append((k, w0))\n",
    "                weights.append((k, w1))\n",
    "            else:\n",
    "                if 'dense' in k:\n",
    "                    w = np.transpose(w)\n",
    "                weights.append((k, w))\n",
    "    if 'relative_attention_bias' in weights[3][0]:\n",
    "        weights = weights[3:4] + weights[:3] + weights[4:]\n",
    "    if not name:\n",
    "        weights = [x[1] for x in weights]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = T5Config(\n",
    "    vocab_size=30000,\n",
    "    # n_positions=self.n_positions,\n",
    "    d_model=2048,\n",
    "    d_ff=5120,\n",
    "    d_kv=2048 // 32,\n",
    "    num_layers=24,\n",
    "    num_heads=32,\n",
    "    relative_attention_num_buckets=32,\n",
    "    dropout_rate=0.0,\n",
    "    initializer_factor=1.0,\n",
    "    eos_token_id=tokenizer.eod_id,\n",
    "    bos_token_id=tokenizer.pad_id,\n",
    "    pad_token_id=tokenizer.pad_id,\n",
    "    decoder_start_token_id=tokenizer.pad_id,\n",
    "    feed_forward_proj='gated-gelu',\n",
    "    tie_word_embeddings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFT5EncoderModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input_ids=tf.constant([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared/shared/weight:0 (30000, 2048)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/relative_attention_bias/embeddings:0 (32, 32)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/q/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/k/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/v/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/o/kernel:0 (2048, 2048)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wi_0/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wi_1/kernel:0 (2048, 5120)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wo/kernel:0 (5120, 2048)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._1/layer_norm/weight:0 (2048,)\n",
      "tf_t5encoder_model/encoder/final_layer_norm/weight:0 (2048,)\n"
     ]
    }
   ],
   "source": [
    "# transformers的T5是把QKV分开的\n",
    "for k in model.variables:\n",
    "    print(k.name, k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.blocks.0.self_attn.self_attn.relative_attention_bias.weight (32, 32)\n",
      "encoder.blocks.0.self_attn.self_attn.project.weight (2048, 2048)\n",
      "encoder.blocks.0.self_attn.self_attn.project.weight (2048, 2048)\n",
      "encoder.blocks.0.self_attn.self_attn.project.weight (2048, 2048)\n",
      "encoder.blocks.0.self_attn.self_attn.dense.weight (2048, 2048)\n",
      "encoder.blocks.0.self_attn.layer_norm.weight (2048,)\n",
      "encoder.blocks.0.ff.dense_relu_dense.wi_0.weight (2048, 5120)\n",
      "encoder.blocks.0.ff.dense_relu_dense.wi_1.weight (2048, 5120)\n",
      "encoder.blocks.0.ff.dense_relu_dense.wo.weight (5120, 2048)\n",
      "encoder.blocks.0.ff.layer_norm.weight (2048,)\n"
     ]
    }
   ],
   "source": [
    "for x in get_block_weight(0, t='encoder', name=True):\n",
    "    print(x[0], x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.blocks.1.self_attn.self_attn.project.weight (2048, 2048)\n",
      "encoder.blocks.1.self_attn.self_attn.project.weight (2048, 2048)\n",
      "encoder.blocks.1.self_attn.self_attn.project.weight (2048, 2048)\n",
      "encoder.blocks.1.self_attn.self_attn.dense.weight (2048, 2048)\n",
      "encoder.blocks.1.self_attn.layer_norm.weight (2048,)\n",
      "encoder.blocks.1.ff.dense_relu_dense.wi_0.weight (2048, 5120)\n",
      "encoder.blocks.1.ff.dense_relu_dense.wi_1.weight (2048, 5120)\n",
      "encoder.blocks.1.ff.dense_relu_dense.wo.weight (5120, 2048)\n",
      "encoder.blocks.1.ff.layer_norm.weight (2048,)\n"
     ]
    }
   ],
   "source": [
    "for x in get_block_weight(1, t='encoder', name=True):\n",
    "    print(x[0], x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new_weights = [get_weight('word_embeds.weight')]\n",
    "for i in range(24):\n",
    "    model_new_weights += get_block_weight(i, t='encoder')\n",
    "model_new_weights += [get_weight('encoder.final_layernorm.weight')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(model_new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.767 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tf.constant([tokenizer.encode('你好')])\n",
    "out = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./tf_eva_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6G\t./tf_eva_encoder\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh './tf_eva_encoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
