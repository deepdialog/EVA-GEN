{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b9ed46-cc24-4ff1-b214-415ca24ae6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jieba sentencepiece transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599147e7-7202-4bd8-be49-24054c6367b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from tokenization_enc_dec import EncDecTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1279e4-8069-4f7c-9974-8db45f4a93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, batch_size = 16, max_len=50):\n",
    "        super(Dataset).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        data = []\n",
    "        data_root = '../chatdata/'\n",
    "        for f in os.listdir(data_root):\n",
    "            data += pickle.load(open(os.path.join(data_root, f), 'rb'))\n",
    "        self.data = data\n",
    "\n",
    "    def random_data(self):\n",
    "        one_data = random.choice(self.data)\n",
    "        lens = random.randint(2, 5)\n",
    "        ind = random.randint(0, len(one_data) - lens - 1)\n",
    "        sentences = one_data[ind:ind+lens]\n",
    "        maxlen = max([len(x) for x in sentences])\n",
    "        if maxlen > 40:\n",
    "            return self.random_data()\n",
    "        s = ''.join(sentences)\n",
    "        if '拜拜' in s or '再见' in s:\n",
    "            if random.random() < 0.95:\n",
    "                return self.random_data()\n",
    "        return sentences\n",
    "\n",
    "    def get_single_data(self, sentences):\n",
    "        input_ids = []\n",
    "        for s in sentences[:-1]:\n",
    "            input_ids += tokenizer.encode(s) + [tokenizer.sep_id]\n",
    "        input_ids += [tokenizer.get_sentinel_id(0)]\n",
    "        y_ids = tokenizer.encode(sentences[-1])\n",
    "        decoder_input_ids = [tokenizer.get_sentinel_id(0)] + y_ids\n",
    "        labels = y_ids + [tokenizer.sep_id]\n",
    "        return torch.LongTensor(input_ids), torch.LongTensor(decoder_input_ids), torch.LongTensor(labels)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        batch_size = self.batch_size\n",
    "        batch = []\n",
    "        keep = np.random.randint(2, 6)\n",
    "        while True:\n",
    "            ids, dids, lbl = self.get_single_data(self.random_data())\n",
    "            batch.append((ids, dids, lbl))\n",
    "            if len(batch) >= batch_size:\n",
    "                input_ids = pad_sequence([\n",
    "                    x[0]\n",
    "                    for x in batch\n",
    "                ], batch_first=True, padding_value=tokenizer.pad_id)\n",
    "                mask = (input_ids != tokenizer.pad_id).to(input_ids.dtype)\n",
    "                decoder_input_ids = pad_sequence([\n",
    "                    x[1]\n",
    "                    for x in batch\n",
    "                ], batch_first=True, padding_value=tokenizer.pad_id)\n",
    "                decoder_mask = (decoder_input_ids != tokenizer.pad_id).to(input_ids.dtype)\n",
    "                # padding -100是源代码里面的magic number， 参考：\n",
    "                # https://github.com/huggingface/transformers/blob/1c06240e1b3477728129bb58e7b6c7734bb5074e/src/transformers/models/t5/modeling_t5.py#L1580\n",
    "                labels = pad_sequence([\n",
    "                    x[2]\n",
    "                    for x in batch\n",
    "                ], batch_first=True, padding_value=-100)\n",
    "                yield input_ids, mask, decoder_input_ids, decoder_mask, labels\n",
    "                batch = []\n",
    "                keep = np.random.randint(2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5155ad2a-c9e2-41b1-a43e-f7a7249e8ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 8.34 s, total: 1min 27s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = T5ForConditionalGeneration.from_pretrained('./torch_eva/')\n",
    "tokenizer = EncDecTokenizer('./EVA/src/bpe_dialog_new/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0026b2c5-12ba-4f70-8d23-d980bcbd706b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 s, sys: 887 ms, total: 2.5 s\n",
      "Wall time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = Dataset(batch_size=16)\n",
    "dl = torch.utils.data.DataLoader(ds, num_workers=8, batch_size=None, pin_memory=True, prefetch_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e28eac4-61a8-478c-975d-8082b1d0ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 41.9 s, total: 2min 14s\n",
      "Wall time: 5.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fp16 = True\n",
    "cuda = True\n",
    "\n",
    "if fp16:\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=1e-3,\n",
    "        momentum=0.9\n",
    "    )\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=1e-3,\n",
    "        momentum=0.9\n",
    "    )\n",
    "if cuda:\n",
    "    if fp16:\n",
    "        model = model.half().cuda()\n",
    "    else:\n",
    "        model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6383cd1c-f502-4065-82d5-d4905faf9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b8601e8-4cf9-4234-aa34-0c662f1bb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5f6a5a-e579-4ac7-87fb-a0b156a71b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...Building prefix dict from the default dictionary ...Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...Loading model from cache /tmp/jieba.cache\n",
      "\n",
      "\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "\n",
      "Loading model from cache /tmp/jieba.cacheLoading model from cache /tmp/jieba.cacheLoading model from cache /tmp/jieba.cacheLoading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cacheLoading model from cache /tmp/jieba.cache\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading model cost 0.836 seconds.Loading model cost 0.835 seconds.\n",
      "\n",
      "Prefix dict has been built successfully.Prefix dict has been built successfully.Loading model cost 0.838 seconds.\n",
      "\n",
      "\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.845 seconds.Loading model cost 0.847 seconds.Loading model cost 0.845 seconds.\n",
      "\n",
      "\n",
      "Prefix dict has been built successfully.Prefix dict has been built successfully.Prefix dict has been built successfully.\n",
      "\n",
      "\n",
      "Loading model cost 0.860 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.982 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "step: 3599 loss: 1.7187: : 3599it [25:02,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 3600 1.8041242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 7199 loss: 1.5582: : 7199it [50:23,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 7200 1.6094422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 10799 loss: 1.4074: : 10799it [1:15:44,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 10800 1.3296105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 14399 loss: 1.3315: : 14399it [1:40:58,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 14400 1.0787582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 17999 loss: 1.2558: : 17999it [2:06:21,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 18000 1.3367486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 21599 loss: 1.2408: : 21599it [2:31:45,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 21600 1.1896592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 25199 loss: 1.2122: : 25199it [2:57:02,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 25200 1.5990603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 28799 loss: 1.2051: : 28799it [3:22:24,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 28800 1.0319228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 32399 loss: 1.1750: : 32399it [3:47:44,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 32400 1.0566983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 35999 loss: 1.1745: : 35999it [4:13:10,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 36000 1.2732273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 39599 loss: 1.1713: : 39599it [4:38:40,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 39600 1.0271161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 43199 loss: 1.1535: : 43199it [5:04:06,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 43200 1.1684688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 46799 loss: 1.1566: : 46799it [5:29:34,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 46800 1.0300099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 50399 loss: 1.1335: : 50399it [5:54:59,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 50400 1.1262554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 53999 loss: 1.1372: : 53999it [6:20:24,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 54000 0.97241783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 57599 loss: 1.1314: : 57599it [6:45:49,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 57600 1.044987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 61199 loss: 1.1301: : 61199it [7:11:12,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 61200 1.1718122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 64799 loss: 1.1209: : 64799it [7:36:39,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 64800 1.1101009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 68399 loss: 1.1219: : 68399it [8:02:02,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 68400 1.236889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 71999 loss: 1.0911: : 71999it [8:27:25,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 72000 0.91616446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 75599 loss: 1.1008: : 75599it [8:52:55,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 75600 1.0377946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 79199 loss: 1.1044: : 79199it [9:18:20,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 79200 1.0226601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 82799 loss: 1.0990: : 82799it [9:43:49,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 82800 1.1966805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 86399 loss: 1.0968: : 86399it [10:09:20,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 86400 1.1003646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 89999 loss: 1.0721: : 89999it [10:34:48,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 90000 1.1350629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 93599 loss: 1.1011: : 93599it [11:00:19,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 93600 1.0899584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 97199 loss: 1.0903: : 97199it [11:25:49,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 97200 1.1363858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 100799 loss: 1.0771: : 100799it [11:51:12,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 100800 1.0004612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 104399 loss: 1.0786: : 104399it [12:16:33,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 104400 1.0684063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 107999 loss: 1.0796: : 107999it [12:42:07,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 108000 1.0564996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 111599 loss: 1.0763: : 111599it [13:07:33,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 111600 0.9773707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 115199 loss: 1.0806: : 115199it [13:33:01,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 115200 1.0635233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 118799 loss: 1.0520: : 118799it [13:58:28,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 118800 0.93359685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 122399 loss: 1.0879: : 122399it [14:23:57,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 122400 1.141929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 125999 loss: 1.0746: : 125999it [14:49:28,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 126000 1.0127586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 129599 loss: 1.0557: : 129599it [15:14:53,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 129600 1.1555089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 133199 loss: 1.0515: : 133199it [15:40:21,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 133200 0.9401102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 136799 loss: 1.0636: : 136799it [16:05:49,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 136800 1.0743293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 140399 loss: 1.0585: : 140399it [16:31:20,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 140400 1.0541804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 143999 loss: 1.0454: : 143999it [16:56:49,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 144000 0.95395374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 147599 loss: 1.0531: : 147599it [17:22:16,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 147600 0.9652821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 151199 loss: 1.0582: : 151199it [17:47:42,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 151200 0.9304118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 154799 loss: 1.0622: : 154799it [18:13:02,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 154800 1.2611653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 158399 loss: 1.0580: : 158399it [18:38:31,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 158400 1.0977086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 161999 loss: 1.0358: : 161999it [19:03:54,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 162000 0.99900043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 165599 loss: 1.0342: : 165599it [19:29:13,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 165600 0.9897446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 169199 loss: 1.0346: : 169199it [19:54:42,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 169200 0.97383714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 172799 loss: 1.0518: : 172799it [20:20:06,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 172800 1.0148427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 176399 loss: 1.0192: : 176399it [20:45:34,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 176400 1.0250503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 176750 loss: 1.0093: : 176751it [20:48:24,  2.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-56f71cf965ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bad loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "losses = []\n",
    "pbar = tqdm(dl)\n",
    "loss_fct2 = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "for x, m0, y, m1, z in pbar:\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        z = z.cuda()\n",
    "        m0 = m0.cuda()\n",
    "        m1 = m1.cuda()\n",
    "    with torch.cuda.amp.autocast():\n",
    "        out = model(\n",
    "            input_ids=x,\n",
    "            attention_mask=m0,\n",
    "            decoder_input_ids=y,\n",
    "            decoder_attention_mask=m1,\n",
    "            # labels=z\n",
    "        )\n",
    "        # loss = out.loss\n",
    "        # loss = loss_fct(out.logits.view(-1, out.logits.size(-1)), z.view(-1))\n",
    "        loss2 = loss_fct2(out.logits.view(-1, out.logits.size(-1)), z.view(-1))\n",
    "        loss = torch.sum(loss2 * (z.view(-1) >= 0)) / torch.sum(z.view(-1) >= 0)\n",
    "\n",
    "    loss.backward()\n",
    "    if torch.isnan(loss) or torch.isinf(loss):\n",
    "        print('bad loss')\n",
    "        optimizer.zero_grad()\n",
    "        continue\n",
    "    else:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    losses.append(loss)\n",
    "    losses = losses[-100:]\n",
    "    pbar.set_description(f'step: {step} loss: {np.mean(losses):.4f}')\n",
    "    step += 1\n",
    "    if step > 0 and step % (60 * 60) == 0:\n",
    "        print('save', step, loss)\n",
    "        torch.save(model.state_dict(), f'model_{step}.pt')\n",
    "        torch.save(optimizer.state_dict(), f'opt_{step}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d36cb-1b1c-4ec7-8e93-425b24f1408b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796fd79-8f20-41e8-8dbb-a23f39128af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
