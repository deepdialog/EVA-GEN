{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions, get_all_providers\n",
    "from tokenization_enc_dec import EncDecTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_for_provider(model_path: str, provider: str= 'CPUExecutionProvider') -> InferenceSession:\n",
    "    assert provider in get_all_providers(), f\"provider {provider} not found, {get_all_providers()}\"\n",
    "    # Few properties that might have an impact on performances (provided by MS)\n",
    "    options = SessionOptions()\n",
    "    options.intra_op_num_threads = 100\n",
    "    options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    # Load the model as a graph and prepare the CPU backend\n",
    "    session = InferenceSession(model_path, options, providers=[provider])\n",
    "    session.disable_fallback()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_model_for_provider('./onnx_eva_q/encoder.onnx')\n",
    "decoder = create_model_for_provider('./onnx_eva_q/decoder.onnx')\n",
    "lm = create_model_for_provider('./onnx_eva_q/lm.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EncDecTokenizer('./EVA/src/bpe_dialog_new/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk(s=['你好'], num_returns=10, top_k=50):\n",
    "    ban = [\n",
    "        5641,  # 京东\n",
    "        4087,  # 客服\n",
    "        2184,  # #\n",
    "        175,   # [\n",
    "        12539, # 小妹\n",
    "        724,   # 客户\n",
    "        1468,  # 商品\n",
    "        6111,  # vi\n",
    "        6454,  # 订单\n",
    "        3748,  # 商家\n",
    "        1548,  # 咨询\n",
    "        6391,  # 发票\n",
    "        681,   # 单\n",
    "        5942,  # 上门\n",
    "    ]\n",
    "    input_ids = []\n",
    "    for ss in s:\n",
    "        input_ids += tokenizer.encode(ss) + [tokenizer.sep_id]\n",
    "    input_ids += [tokenizer.get_sentinel_id(0)]\n",
    "    input_ids = np.array([input_ids])\n",
    "    mask = np.ones_like(input_ids)\n",
    "    encoder_last_hidden_state = encoder.run(['last_hidden_state'], {\n",
    "        \"input_ids\": input_ids, \"attention_mask\": mask\n",
    "    })[0]\n",
    "    encoder_last_hidden_state = np.repeat(encoder_last_hidden_state, num_returns, axis=0)\n",
    "    mask = np.repeat(mask, num_returns, axis=0)\n",
    "    decoder_input_ids = np.repeat(np.array([[tokenizer.get_sentinel_id(0)]]), num_returns, axis=0)\n",
    "    decoder_mask = np.ones_like(decoder_input_ids)\n",
    "    choice_inds = list(range(top_k))\n",
    "    all_probs = []\n",
    "    for i in range(64):\n",
    "        decoder_last_hidden_state = decoder.run(['last_hidden_state'], {\n",
    "            \"decoder_input_ids\": decoder_input_ids,\n",
    "            \"decoder_attention_mask\": decoder_mask,\n",
    "            'encoder_hidden_states': encoder_last_hidden_state,\n",
    "            'encoder_attention_mask': mask,\n",
    "        })[0]\n",
    "        logits = lm.run(['logits'], { 'decoder_hidden_states': decoder_last_hidden_state, })[0]\n",
    "\n",
    "        for x in ban:\n",
    "            logits[:, -1, x] = -9999\n",
    "\n",
    "        scores = softmax(logits[:, -1, :])\n",
    "        next_probs = np.sort(scores)[:, ::-1][:, :top_k]\n",
    "        next_probs_1 = next_probs / next_probs.sum(axis=1).reshape((-1, 1))\n",
    "        next_tokens = np.argsort(scores)[:, ::-1][:, :top_k]\n",
    "        inds = [\n",
    "            np.random.choice(choice_inds, p=next_probs_1[0])\n",
    "            for _ in range(num_returns)\n",
    "        ]\n",
    "        next_tokens = [\n",
    "            x[i]\n",
    "            for x, i in zip(next_tokens, inds)\n",
    "        ]\n",
    "        next_probs = [\n",
    "            x[i]\n",
    "            for x, i in zip(next_probs, inds)\n",
    "        ]\n",
    "        all_probs.append(np.log(next_probs))\n",
    "        decoder_input_ids = np.concatenate([\n",
    "            decoder_input_ids,\n",
    "            np.array(next_tokens).reshape((num_returns, 1))\n",
    "        ], axis=1)\n",
    "        if np.sum(np.sum(decoder_input_ids == tokenizer.sep_id, axis=1) > 0) >= num_returns:\n",
    "            break\n",
    "    all_probs = np.array(all_probs).transpose()\n",
    "    decoder_input_ids = decoder_input_ids[:, 1:]\n",
    "    rets = []\n",
    "    for i, ind in enumerate(np.argmax(decoder_input_ids == 4, axis=1)):\n",
    "        decoder_input_ids[i, ind:] = 0\n",
    "        rets.append(tokenizer.decode(decoder_input_ids[i, :ind]))\n",
    "    final_scores = np.sum((decoder_input_ids > 0) * all_probs, axis=1)\n",
    "    return rets, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['您好,请问有什么可以帮助您的吗?']\n",
      "['请问您是要换绑手机号还是签收信息']\n",
      "['我在吃饭']\n",
      "['亲爱的,请问有什么问题我可以帮您处理或解决呢?您好']\n",
      "['您好,您可以看下您的地址和电话吗?']\n",
      "['请问您是要问问题什么吗']\n",
      "['您好,亲爱的有什么可以为您效劳的呢']\n",
      "['好久没有跟大家见面,今天跟大家一起分享我这段时间的所感所想。']\n",
      "['亲亲您好,有什么问题我可以帮您处理或解决呢?']\n",
      "['您好,请问有什么可以帮助您?']\n",
      "CPU times: user 4min 31s, sys: 73.6 ms, total: 4min 31s\n",
      "Wall time: 6.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    r = talk(['你好啊'], 1)\n",
    "    print(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
